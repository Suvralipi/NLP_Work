{"cells":[{"metadata":{"id":"U-2zaYDuFEk7","outputId":"3a5e264d-73d8-4654-c1e1-559a23e62fd6","trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('wordnet')","execution_count":45,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","name":"stdout"},{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"id":"5E5J3jbMETXC","trusted":true},"cell_type":"code","source":"!pip install transformers\nimport nltk\nnltk.download('punkt')\n# !pip install nltk\n","execution_count":46,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2020.11.13)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.43)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.55.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.8)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\nRequirement already satisfied: tokenizers==0.9.4 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.9.4)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.12.5)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.2)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","name":"stdout"},{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"id":"6GbqX4epD7NM","trusted":true},"cell_type":"code","source":"import torch\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nimport numpy as np\nfrom transformers import BertTokenizer\nfrom torch.utils.data import TensorDataset\nimport random\nfrom nltk import sent_tokenize\nfrom transformers import BertForSequenceClassification\n\ndf = pd.read_csv('../input/sentiment-training/Senti_training.csv')\n# df.head()\n# data=pd.read_excel('issue.xlsx')","execution_count":47,"outputs":[]},{"metadata":{"id":"nZPQKoJCBjjo","trusted":true},"cell_type":"code","source":"df.head()","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"   Unnamed: 0                                  Issue Experienced Sub Reason  \\\n0           7  Always very satisfied with Your products. Alth...      other   \n1          44  Ease of access and relevant offers that suit m...      other   \n2          63  It is easy for me to manage as I am not great ...      other   \n3          68                                     Excellent site      other   \n4         145                                               Easy      other   \n\n   Problem statement Sentiment  \n0  positive feedback  Positive  \n1  positive feedback  Positive  \n2  positive feedback  Positive  \n3  positive feedback  Positive  \n4  positive feedback  Positive  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Issue Experienced</th>\n      <th>Sub Reason</th>\n      <th>Problem statement</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>Always very satisfied with Your products. Alth...</td>\n      <td>other</td>\n      <td>positive feedback</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44</td>\n      <td>Ease of access and relevant offers that suit m...</td>\n      <td>other</td>\n      <td>positive feedback</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>63</td>\n      <td>It is easy for me to manage as I am not great ...</td>\n      <td>other</td>\n      <td>positive feedback</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>68</td>\n      <td>Excellent site</td>\n      <td>other</td>\n      <td>positive feedback</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>145</td>\n      <td>Easy</td>\n      <td>other</td>\n      <td>positive feedback</td>\n      <td>Positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"id":"6P1zwLfWD7NQ","outputId":"925b712b-8a33-4c5a-ee89-ff385f22f139","trusted":true},"cell_type":"code","source":"data=df[['Issue Experienced', 'Sentiment']]\ndata['Sentiment'].value_counts()","execution_count":49,"outputs":[{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"Positive    4835\nNegative    4835\nName: Sentiment, dtype: int64"},"metadata":{}}]},{"metadata":{"id":"xwvy21XvD7NT","outputId":"5f779976-5337-4c3c-ffbd-409b25dea32a","trusted":true},"cell_type":"code","source":"data['Sentiment']=data['Sentiment'].apply(lambda x: str(x).lower())\n#data.loc[data['Sentiment'] == 'covid', 'Sub Reason'] = 'covid-19'\npossible_labels = data['Sentiment'].unique()\n\nlabel_dict = {}\nfor index, possible_label in enumerate(possible_labels):\n    label_dict[possible_label] = index\nprint(label_dict)\ndata['Sentiment'].value_counts()\n","execution_count":50,"outputs":[{"output_type":"stream","text":"{'positive': 0, 'negative': 1}\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n","name":"stderr"},{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"positive    4835\nnegative    4835\nName: Sentiment, dtype: int64"},"metadata":{}}]},{"metadata":{"id":"7kpHRDe_D7NW","outputId":"6b56a9b9-5d08-46b0-af5b-b3017ba1bc74","trusted":true},"cell_type":"code","source":"data['label'] = data['Sentiment'].replace(label_dict)\nprint(data['Sentiment'].value_counts())\next=[]\nprint(data['Sentiment'].value_counts())","execution_count":51,"outputs":[{"output_type":"stream","text":"positive    4835\nnegative    4835\nName: Sentiment, dtype: int64\npositive    4835\nnegative    4835\nName: Sentiment, dtype: int64\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n","name":"stderr"}]},{"metadata":{"id":"WXB6TBcmD7Nb","trusted":true},"cell_type":"code","source":"new_aug_data=[]\nfor i in data[data['label'].isin(ext)].itertuples():\n    \n    aug_ext=set(eda(i._1,alpha_rs=0.00001,p_rd=0.00,alpha_ri=0.001))\n    \n    for j in aug_ext:\n        dum=[]\n        dum.append(j)\n        dum.append(i._2)\n        dum.append(i.label)\n        new_aug_data.append(dum)\nprint(data['Sentiment'].value_counts())","execution_count":52,"outputs":[{"output_type":"stream","text":"positive    4835\nnegative    4835\nName: Sentiment, dtype: int64\n","name":"stdout"}]},{"metadata":{"id":"156ZeiTuD7Ne","trusted":true},"cell_type":"code","source":"new_df=pd.DataFrame(new_aug_data,columns=['Issue Experienced','Sentiment','label'])\nprint(new_df['Sentiment'].value_counts())\ndata=pd.concat([data,new_df])\nprint(data['Sentiment'].value_counts())","execution_count":53,"outputs":[{"output_type":"stream","text":"Series([], Name: Sentiment, dtype: int64)\npositive    4835\nnegative    4835\nName: Sentiment, dtype: int64\n","name":"stdout"}]},{"metadata":{"id":"Zif6_JT3-rjT","outputId":"2072aaf6-90da-48c3-d966-6ed19aaaf30f","trusted":true},"cell_type":"code","source":"#data.loc[data['label'].isin([5,10,12,13]), 'label'] = 0","execution_count":54,"outputs":[]},{"metadata":{"id":"bYjH9iCAV4hb","trusted":true},"cell_type":"code","source":"#data=data[data['Sub Reason']!='other']","execution_count":55,"outputs":[]},{"metadata":{"id":"E2kEFfnAHYgP","outputId":"96c6d1ce-b32c-4c2e-ba93-b3c2b8f58fb7","trusted":true},"cell_type":"code","source":"data","execution_count":56,"outputs":[{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"                                      Issue Experienced Sentiment label\n0     Always very satisfied with Your products. Alth...  positive     0\n1     Ease of access and relevant offers that suit m...  positive     0\n2     It is easy for me to manage as I am not great ...  positive     0\n3                                        Excellent site  positive     0\n4                                                  Easy  positive     0\n...                                                 ...       ...   ...\n9665  Told I would be sent a link to reset my passwo...  negative     1\n9666  Today I purchases for 90.26 GBP but £5off not ...  negative     1\n9667  Thanks, but I do NOT want an avocado. I’m stil...  negative     1\n9668  We are disappointed with the Vegetarian Main c...  negative     1\n9669  Unable to add items to my cart, even though th...  negative     1\n\n[9670 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Issue Experienced</th>\n      <th>Sentiment</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Always very satisfied with Your products. Alth...</td>\n      <td>positive</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ease of access and relevant offers that suit m...</td>\n      <td>positive</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>It is easy for me to manage as I am not great ...</td>\n      <td>positive</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Excellent site</td>\n      <td>positive</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Easy</td>\n      <td>positive</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9665</th>\n      <td>Told I would be sent a link to reset my passwo...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9666</th>\n      <td>Today I purchases for 90.26 GBP but £5off not ...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9667</th>\n      <td>Thanks, but I do NOT want an avocado. I’m stil...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9668</th>\n      <td>We are disappointed with the Vegetarian Main c...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9669</th>\n      <td>Unable to add items to my cart, even though th...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>9670 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"id":"obZswko6Gkm_","trusted":true},"cell_type":"code","source":"shuf_data=[]\nfor i,row in data.iterrows():\n  dum=[]\n  sent=sent_tokenize(row['Issue Experienced'])\n  if len(sent)>1:\n    random.shuffle(sent)\n    dum.append(''.join(sent))\n    dum.append(row['Sentiment'])\n    dum.append(row['label'])\n    shuf_data.append(dum)","execution_count":57,"outputs":[]},{"metadata":{"id":"1ZziG7XqIHOj","trusted":true},"cell_type":"code","source":"sf=pd.DataFrame(shuf_data,columns=data.columns)","execution_count":58,"outputs":[]},{"metadata":{"id":"HfsM4IlDIgRa","trusted":true},"cell_type":"code","source":"data=pd.concat([data,sf])","execution_count":59,"outputs":[]},{"metadata":{"id":"yv114G2FYUtX","outputId":"9b50a388-ac28-4534-feae-1ac3463f3f22","trusted":true},"cell_type":"code","source":"print(data['Sentiment'].value_counts())","execution_count":60,"outputs":[{"output_type":"stream","text":"negative    8234\npositive    6244\nName: Sentiment, dtype: int64\n","name":"stdout"}]},{"metadata":{"id":"2sJiB4u2Ipd2","outputId":"b652a31d-1c39-4d24-b0b9-34bfe712574b","trusted":true},"cell_type":"code","source":"data.shape","execution_count":61,"outputs":[{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"(14478, 3)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":62,"outputs":[{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"                                      Issue Experienced Sentiment label\n0     Always very satisfied with Your products. Alth...  positive     0\n1     Ease of access and relevant offers that suit m...  positive     0\n2     It is easy for me to manage as I am not great ...  positive     0\n3                                        Excellent site  positive     0\n4                                                  Easy  positive     0\n...                                                 ...       ...   ...\n4803  She is 95 but loves clothes.I am trying to rep...  negative     1\n4804  Told I would be sent a link to reset my passwo...  negative     1\n4805  I’m still not impressed with Sparks offers.Tha...  negative     1\n4806  We are disappointed with the Vegetarian Main c...  negative     1\n4807  Had to shop elsewhereUnable to add items to my...  negative     1\n\n[14478 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Issue Experienced</th>\n      <th>Sentiment</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Always very satisfied with Your products. Alth...</td>\n      <td>positive</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ease of access and relevant offers that suit m...</td>\n      <td>positive</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>It is easy for me to manage as I am not great ...</td>\n      <td>positive</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Excellent site</td>\n      <td>positive</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Easy</td>\n      <td>positive</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4803</th>\n      <td>She is 95 but loves clothes.I am trying to rep...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4804</th>\n      <td>Told I would be sent a link to reset my passwo...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4805</th>\n      <td>I’m still not impressed with Sparks offers.Tha...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4806</th>\n      <td>We are disappointed with the Vegetarian Main c...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4807</th>\n      <td>Had to shop elsewhereUnable to add items to my...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>14478 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos=data[data['label']==0]\nneg=data[data['label']==1]","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(pos.shape)\nprint(neg.shape)\nneg=neg[0:6244]\nprint(neg.shape)\n","execution_count":64,"outputs":[{"output_type":"stream","text":"(6244, 3)\n(8234, 3)\n(6244, 3)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"frame=[pos,neg]\nfinal=pd.concat(frame)\nfinal['label'].value_counts()","execution_count":65,"outputs":[{"output_type":"execute_result","execution_count":65,"data":{"text/plain":"0    6244\n1    6244\nName: label, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/sentiment-test-data/Senti_test_data.csv')\ntest['label']=test['Sentiment'].apply(lambda x: 1 if x =='Negative' else 0)\nprint(test.columns)\nprint(final.columns)","execution_count":66,"outputs":[{"output_type":"stream","text":"Index(['Unnamed: 0', 'Issue Experienced', 'Sub Reason', 'Problem statement',\n       'Sentiment', 'label'],\n      dtype='object')\nIndex(['Issue Experienced', 'Sentiment', 'label'], dtype='object')\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"final['label']=final['label'].apply(lambda x: int(x))\ntest['label']=test['label'].apply(lambda x: int(x))\nfinal['Issue Experienced']=final['Issue Experienced'].apply(lambda x: str(x))\ntest['Issue Experienced']=test['Issue Experienced'].apply(lambda x: str(x))","execution_count":95,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=final['Issue Experienced']\nX_val=test['Issue Experienced']\ny_train=final['label']\ny_val=test['label']","execution_count":96,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train)\nprint(X_val.dtype)\nprint(y_train.dtype)\nprint(y_val.dtype)","execution_count":97,"outputs":[{"output_type":"stream","text":"0       Always very satisfied with Your products. Alth...\n1       Ease of access and relevant offers that suit m...\n2       It is easy for me to manage as I am not great ...\n3                                          Excellent site\n4                                                    Easy\n                              ...                        \n2813    Please advise.The pocket spring single mattres...\n2814    Too-way stretch cup T-shirt bras not made any ...\n2815    I like the web site but no information about t...\n2816    Rosemary ClevettKind regards.I placed an order...\n2817    Why are you trying to encourage people in to y...\nName: Issue Experienced, Length: 12488, dtype: object\nobject\nint64\nint64\n","name":"stdout"}]},{"metadata":{"id":"8Uf0gqJfD7Nh","trusted":true},"cell_type":"code","source":"\"\"\"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(data.index.values, \n                                                  data.label.values, \n                                                  test_size=0.15, \n                                                  random_state=42, \n                                                  stratify=data.label.values)\n\n#data['data_type'] = ['not_set']*data.shape[0]\"\"\"\n\nfinal['data_type'] = 'train'\ntest['data_type'] = 'val'\n","execution_count":98,"outputs":[]},{"metadata":{"id":"MVVgjwNpD7Ns","trusted":true},"cell_type":"code","source":"#data.groupby(['Sub Reason','label', 'data_type']).count()","execution_count":99,"outputs":[]},{"metadata":{"id":"L0bc_MUsD7Nu","outputId":"e6f2a423-0e73-451b-9d81-9f1c95bbba7c","trusted":true},"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n                                          do_lower_case=True)\n                                          \nencoded_data_train = tokenizer.batch_encode_plus(\n    final[final.data_type=='train']['Issue Experienced'].values, \n    add_special_tokens=True, \n    return_attention_mask=True, \n    pad_to_max_length=True, \n    max_length=256,\n    truncation=True, \n    return_tensors='pt'\n)\n\nencoded_data_val = tokenizer.batch_encode_plus(\n    test[test.data_type=='val']['Issue Experienced'].values, \n    add_special_tokens=True, \n    return_attention_mask=True, \n    pad_to_max_length=True, \n    max_length=256, \n    truncation=True, \n    return_tensors='pt'\n)\n\n\ninput_ids_train = encoded_data_train['input_ids']\nattention_masks_train = encoded_data_train['attention_mask']\nlabels_train = torch.tensor(final[final.data_type=='train'].label.values)\n\ninput_ids_val = encoded_data_val['input_ids']\nattention_masks_val = encoded_data_val['attention_mask']\nlabels_val = torch.tensor(test[test.data_type=='val'].label.values)\n\ndataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\ndataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)","execution_count":102,"outputs":[]},{"metadata":{"id":"NnPEGK6kCbPf","trusted":true},"cell_type":"code","source":"# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n                                          \n# encoded_data_train = tokenizer.batch_encode_plus(\n#     data[data.data_type=='train']['filtered SR'].values, \n#     add_special_tokens=True, \n#     return_attention_mask=True, \n#     pad_to_max_length=True, \n#     max_length=500,\n#     truncation=True, \n#     return_tensors='pt'\n# )\n\n# encoded_data_val = tokenizer.batch_encode_plus(\n#     data[data.data_type=='val']['filtered SR'].values, \n#     add_special_tokens=True, \n#     return_attention_mask=True, \n#     pad_to_max_length=True, \n#     max_length=500, \n#     truncation=True, \n#     return_tensors='pt'\n# )\n\n\n# input_ids_train = encoded_data_train['input_ids']\n# attention_masks_train = encoded_data_train['attention_mask']\n# labels_train = torch.tensor(data[data.data_type=='train'].label.values)\n\n# input_ids_val = encoded_data_val['input_ids']\n# attention_masks_val = encoded_data_val['attention_mask']\n# labels_val = torch.tensor(data[data.data_type=='val'].label.values)\n\n# dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n# dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)","execution_count":103,"outputs":[]},{"metadata":{"id":"j-_FFAcHD7Nx","outputId":"cac3fdbb-c515-4384-cadb-6c0c74b3bd21","trusted":true},"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=len(label_dict),\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)","execution_count":104,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba499f34da064055b1ee5d4bd1948e1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b6d17ceab0b428e9a80df8b333e8c72"}},"metadata":{}},{"output_type":"stream","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","name":"stderr"}]},{"metadata":{"id":"-8UUmrP6D7N2","trusted":true},"cell_type":"code","source":"# set(eda('i didnot receive the gift', alpha_rs=0.00001,p_rd=0.00,alpha_ri=0.001))\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n\nbatch_size = 3\n\ndataloader_train = DataLoader(dataset_train, \n                              sampler=RandomSampler(dataset_train), \n                              batch_size=batch_size)\n\ndataloader_validation = DataLoader(dataset_val, \n                                   sampler=SequentialSampler(dataset_val), \n                                   batch_size=batch_size)","execution_count":105,"outputs":[]},{"metadata":{"id":"zQz_ti8HD7N5","trusted":true},"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup\n\noptimizer = AdamW(model.parameters(),\n                  lr=1e-5, \n                  eps=1e-8)\n                  \nepochs = 5\n\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=0,\n                                            num_training_steps=len(dataloader_train)*epochs)","execution_count":106,"outputs":[]},{"metadata":{"id":"P_1BscehD7N7","trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef f1_score_func(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef accuracy_per_class(preds, labels):\n    label_dict_inverse = {v: k for k, v in label_dict.items()}\n    \n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n\n    for label in np.unique(labels_flat):\n        y_preds = preds_flat[labels_flat==label]\n        y_true = labels_flat[labels_flat==label]\n        print(f'Class: {label_dict_inverse[label]}')\n        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')","execution_count":107,"outputs":[]},{"metadata":{"id":"_h0nYybpD7OC","outputId":"412fe4aa-bbf7-4bef-f734-4dd60e945fac","trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\nprint(device)","execution_count":108,"outputs":[{"output_type":"stream","text":"cpu\n","name":"stdout"}]},{"metadata":{"id":"ludBtfMYD7OE","trusted":true},"cell_type":"code","source":"def evaluate(dataloader_val):\n\n    model.eval()\n    \n    loss_val_total = 0\n    predictions, true_vals = [], []\n    \n    for batch in tqdm(dataloader_val):\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }\n\n        with torch.no_grad():        \n            outputs = model(**inputs)\n            \n        loss = outputs[0]\n        logits = outputs[1]\n        loss_val_total += loss.item()\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = inputs['labels'].cpu().numpy()\n        predictions.append(logits)\n        true_vals.append(label_ids)\n    \n    loss_val_avg = loss_val_total/len(dataloader_val) \n    \n    predictions = np.concatenate(predictions, axis=0)\n    true_vals = np.concatenate(true_vals, axis=0)\n            \n    return loss_val_avg, predictions, true_vals","execution_count":109,"outputs":[]},{"metadata":{"id":"JPIG9Zq-UXm6","outputId":"263aaf93-7cf4-41e4-9e28-b1deeea0ff29","trusted":true},"cell_type":"code","source":"final['Sentiment'].value_counts()","execution_count":110,"outputs":[{"output_type":"execute_result","execution_count":110,"data":{"text/plain":"negative    8234\npositive    6244\nName: Sentiment, dtype: int64"},"metadata":{}}]},{"metadata":{"id":"KC0WA2ALD7OK","outputId":"fb8c9201-81bc-4a26-e7ca-d1e4837bc4ad","trusted":false},"cell_type":"code","source":"for epoch in tqdm(range(1, epochs+1)):\n    model.train()\n    \n    loss_train_total = 0\n    progress_bar = tqdm(dataloader_train,\n                        desc=\"Epoch {:1d}\".format(epoch),\n                        leave=False,\n                        disable=False)\n    \n    for batch in progress_bar:\n        model.zero_grad()\n        batch = tuple(b.to(device) for b in batch)\n        inputs = {\n            'input_ids'       : batch[0],\n            'attention_mask'  : batch[1],\n            'labels'          : batch[2]\n        }\n    \n        outputs = model(**inputs)\n        loss = outputs[0]\n        loss_train_total += loss.item()\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n\n        optimizer.step()\n        scheduler.step()\n\n        progress_bar.set_postfix( {'training_loss': '{:3f}'.format(loss.item() / len(batch))} )\n\n    torch.save(model.state_dict(), 'BERT_ft_epoch{}.model'.format(epoch))\n    tqdm.write('\\nEpoch {epoch}')\n    \n    loss_train_avg = loss_train_total / len(dataloader_train)\n    tqdm.write('Training loss: {}'.format(loss_train_avg))\n    \n    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n    val_f1 = f1_score_func(predictions, true_vals)\n    val_acc=accuracy_per_class(predictions, true_vals)\n    \n    tqdm.write('Validation loss: {}'.format(val_loss))\n    tqdm.write('f1 score (weighted): {}'.format(val_f1))\n    # tqdm.write(val_acc)","execution_count":null,"outputs":[]},{"metadata":{"id":"hA1Hk8QBD7ON","trusted":false},"cell_type":"code","source":"\n# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n#                                                       num_labels=len(label_dict),\n#                                                       output_attentions=False,\n#                                                       output_hidden_states=False)\n_, predictions, true_vals = evaluate(dataloader_validation)\naccuracy_per_class(predictions, true_vals)","execution_count":null,"outputs":[]},{"metadata":{"id":"sauK2dq0BJzf","outputId":"0b32bc58-f9ed-4791-c80b-dff1104035e9","trusted":false},"cell_type":"code","source":"import random\nfrom nltk import sent_tokenize\nsen=sent_tokenize('I am b2. hello i am going to kill you. a ')\nrandom.shuffle(sen)\nsen","execution_count":null,"outputs":[]},{"metadata":{"id":"wSVFylHWBS6q","outputId":"204034f0-0437-4d57-aeed-4290f991e4d3","trusted":false},"cell_type":"code","source":"random.shuffle(['a','b','c'])","execution_count":null,"outputs":[]},{"metadata":{"id":"fSG1lVbYB0l4","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}