{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U-2zaYDuFEk7",
    "outputId": "3a5e264d-73d8-4654-c1e1-559a23e62fd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5E5J3jbMETXC"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "# !pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GbqX4epD7NM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "import random\n",
    "from nltk import sent_tokenize\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "df = pd.read_csv('Issue_tree_sentiment__no_error (1).tsv', delimiter = '\\t', quoting = 3)\n",
    "# df.head()\n",
    "# data=pd.read_excel('issue.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZPQKoJCBjjo"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6P1zwLfWD7NQ",
    "outputId": "925b712b-8a33-4c5a-ee89-ff385f22f139"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparksandPromotions                4922\n",
       "Other                              3878\n",
       "Navigation                         3851\n",
       "Stock                              3555\n",
       "CheckoutandLogin                   2828\n",
       "ProductRange                       2521\n",
       "DeliveryInformationandMyAccount    2110\n",
       "MissingContentorImagery            1614\n",
       "OrderandCommunication              1544\n",
       "Search                             1453\n",
       "TechnicalIssue                      821\n",
       "SitePerformance                     536\n",
       "General                             136\n",
       "COVID-19                             33\n",
       "Covid                                 5\n",
       "other                                 5\n",
       "navigation                            5\n",
       "checkoutandlogin                      4\n",
       "search                                4\n",
       "sparksandpromotions                   3\n",
       "checkoutandLogin                      3\n",
       "productrange                          2\n",
       "stock                                 2\n",
       "missingcontentorimagery               2\n",
       "deliveryinformationandmyaccount       1\n",
       "covid                                 1\n",
       "Name: Sub Reason, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df[['Issue Experienced', 'Sub Reason']]\n",
    "data['Sub Reason'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwvy21XvD7NT",
    "outputId": "5f779976-5337-4c3c-ffbd-409b25dea32a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'siteperformance': 0, 'stock': 1, 'orderandcommunication': 2, 'search': 3, 'navigation': 4, 'other': 5, 'deliveryinformationandmyaccount': 6, 'sparksandpromotions': 7, 'productrange': 8, 'missingcontentorimagery': 9, 'technicalissue': 10, 'checkoutandlogin': 11, 'covid-19': 12, 'general ': 13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sparksandpromotions                4925\n",
       "other                              3883\n",
       "navigation                         3856\n",
       "stock                              3557\n",
       "checkoutandlogin                   2835\n",
       "productrange                       2523\n",
       "deliveryinformationandmyaccount    2111\n",
       "missingcontentorimagery            1616\n",
       "orderandcommunication              1544\n",
       "search                             1457\n",
       "technicalissue                      821\n",
       "siteperformance                     536\n",
       "general                             136\n",
       "covid-19                             39\n",
       "Name: Sub Reason, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sub Reason']=data['Sub Reason'].apply(lambda x: str(x).lower())\n",
    "data.loc[data['Sub Reason'] == 'covid', 'Sub Reason'] = 'covid-19'\n",
    "possible_labels = data['Sub Reason'].unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "print(label_dict)\n",
    "data['Sub Reason'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kpHRDe_D7NW",
    "outputId": "6b56a9b9-5d08-46b0-af5b-b3017ba1bc74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparksandpromotions                4925\n",
      "other                              3883\n",
      "navigation                         3856\n",
      "stock                              3557\n",
      "checkoutandlogin                   2835\n",
      "productrange                       2523\n",
      "deliveryinformationandmyaccount    2111\n",
      "missingcontentorimagery            1616\n",
      "orderandcommunication              1544\n",
      "search                             1457\n",
      "technicalissue                      821\n",
      "siteperformance                     536\n",
      "general                             136\n",
      "covid-19                             39\n",
      "Name: Sub Reason, dtype: int64\n",
      "other                              5415\n",
      "sparksandpromotions                4925\n",
      "navigation                         3856\n",
      "stock                              3557\n",
      "checkoutandlogin                   2835\n",
      "productrange                       2523\n",
      "deliveryinformationandmyaccount    2111\n",
      "missingcontentorimagery            1616\n",
      "orderandcommunication              1544\n",
      "search                             1457\n",
      "Name: Sub Reason, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "data['label'] = data['Sub Reason'].replace(label_dict)\n",
    "print(data['Sub Reason'].value_counts())\n",
    "ext=[]\n",
    "for i,j in  data['Sub Reason'].value_counts().items():\n",
    "    if j <1000:\n",
    "        # ext.append(i)\n",
    "        data.loc[data['Sub Reason'] == i, 'Sub Reason'] = 'other'\n",
    "print(data['Sub Reason'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXB6TBcmD7Nb"
   },
   "outputs": [],
   "source": [
    "new_aug_data=[]\n",
    "for i in data[data['label'].isin(ext)].itertuples():\n",
    "    \n",
    "    aug_ext=set(eda(i._1,alpha_rs=0.00001,p_rd=0.00,alpha_ri=0.001))\n",
    "    \n",
    "    for j in aug_ext:\n",
    "        dum=[]\n",
    "        dum.append(j)\n",
    "        dum.append(i._2)\n",
    "        dum.append(i.label)\n",
    "        new_aug_data.append(dum)\n",
    "print(data['Sub Reason'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "156ZeiTuD7Ne"
   },
   "outputs": [],
   "source": [
    "new_df=pd.DataFrame(new_aug_data,columns=['Issue Experienced','Sub Reason','label'])\n",
    "print(new_df['Sub Reason'].value_counts())\n",
    "data=pd.concat([data,new_df])\n",
    "print(data['Sub Reason'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zif6_JT3-rjT",
    "outputId": "2072aaf6-90da-48c3-d966-6ed19aaaf30f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "data.loc[data['label'].isin([5,10,12,13]), 'label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYjH9iCAV4hb"
   },
   "outputs": [],
   "source": [
    "data=data[data['Sub Reason']!='other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "E2kEFfnAHYgP",
    "outputId": "96c6d1ce-b32c-4c2e-ba93-b3c2b8f58fb7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue Experienced</th>\n",
       "      <th>Sub Reason</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After ordering yesterday a skirt and jumper I ...</td>\n",
       "      <td>stock</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Issue Experienced Sub Reason  label\n",
       "1  After ordering yesterday a skirt and jumper I ...      stock      1"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obZswko6Gkm_"
   },
   "outputs": [],
   "source": [
    "shuf_data=[]\n",
    "for i,row in data.iterrows():\n",
    "  dum=[]\n",
    "  sent=sent_tokenize(row['Issue Experienced'])\n",
    "  if len(sent)>1:\n",
    "    random.shuffle(sent)\n",
    "    dum.append(''.join(sent))\n",
    "    dum.append(row['Sub Reason'])\n",
    "    dum.append(row['label'])\n",
    "    shuf_data.append(dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZziG7XqIHOj"
   },
   "outputs": [],
   "source": [
    "sf=pd.DataFrame(shuf_data,columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HfsM4IlDIgRa"
   },
   "outputs": [],
   "source": [
    "data=pd.concat([data,sf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yv114G2FYUtX",
    "outputId": "9b50a388-ac28-4534-feae-1ac3463f3f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparksandpromotions                7812\n",
      "other                              7612\n",
      "navigation                         6155\n",
      "stock                              5977\n",
      "checkoutandlogin                   4623\n",
      "productrange                       4338\n",
      "deliveryinformationandmyaccount    3594\n",
      "missingcontentorimagery            2715\n",
      "orderandcommunication              2548\n",
      "search                             2337\n",
      "Name: Sub Reason, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Sub Reason'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sJiB4u2Ipd2",
    "outputId": "b652a31d-1c39-4d24-b0b9-34bfe712574b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40099, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Uf0gqJfD7Nh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(data.index.values, \n",
    "                                                  data.label.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=data.label.values)\n",
    "\n",
    "data['data_type'] = ['not_set']*data.shape[0]\n",
    "\n",
    "data.loc[X_train, 'data_type'] = 'train'\n",
    "data.loc[X_val, 'data_type'] = 'val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVVgjwNpD7Ns"
   },
   "outputs": [],
   "source": [
    "data.groupby(['Sub Reason','label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "0b2ef832d9b84dcba2d17ee03dc47609"
     ]
    },
    "id": "L0bc_MUsD7Nu",
    "outputId": "e6f2a423-0e73-451b-9d81-9f1c95bbba7c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2ef832d9b84dcba2d17ee03dc47609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)\n",
    "                                          \n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    data[data.data_type=='train']['Issue Experienced'].values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256,\n",
    "    truncation=True, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    data[data.data_type=='val']['Issue Experienced'].values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    truncation=True, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(data[data.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(data[data.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NnPEGK6kCbPf"
   },
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "                                          \n",
    "# encoded_data_train = tokenizer.batch_encode_plus(\n",
    "#     data[data.data_type=='train']['filtered SR'].values, \n",
    "#     add_special_tokens=True, \n",
    "#     return_attention_mask=True, \n",
    "#     pad_to_max_length=True, \n",
    "#     max_length=500,\n",
    "#     truncation=True, \n",
    "#     return_tensors='pt'\n",
    "# )\n",
    "\n",
    "# encoded_data_val = tokenizer.batch_encode_plus(\n",
    "#     data[data.data_type=='val']['filtered SR'].values, \n",
    "#     add_special_tokens=True, \n",
    "#     return_attention_mask=True, \n",
    "#     pad_to_max_length=True, \n",
    "#     max_length=500, \n",
    "#     truncation=True, \n",
    "#     return_tensors='pt'\n",
    "# )\n",
    "\n",
    "\n",
    "# input_ids_train = encoded_data_train['input_ids']\n",
    "# attention_masks_train = encoded_data_train['attention_mask']\n",
    "# labels_train = torch.tensor(data[data.data_type=='train'].label.values)\n",
    "\n",
    "# input_ids_val = encoded_data_val['input_ids']\n",
    "# attention_masks_val = encoded_data_val['attention_mask']\n",
    "# labels_val = torch.tensor(data[data.data_type=='val'].label.values)\n",
    "\n",
    "# dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "# dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "da9a0c03fa024545b500167a240cf21a",
      "fc0f7f9529534b57863538b3036bcd6d"
     ]
    },
    "collapsed": true,
    "id": "j-_FFAcHD7Nx",
    "outputId": "cac3fdbb-c515-4384-cadb-6c0c74b3bd21"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9a0c03fa024545b500167a240cf21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0f7f9529534b57863538b3036bcd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8UUmrP6D7N2"
   },
   "outputs": [],
   "source": [
    "# set(eda('i didnot receive the gift', alpha_rs=0.00001,p_rd=0.00,alpha_ri=0.001))\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQz_ti8HD7N5"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)\n",
    "                  \n",
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_1BscehD7N7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_h0nYybpD7OC",
    "outputId": "412fe4aa-bbf7-4bef-f734-4dd60e945fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ludBtfMYD7OE"
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in tqdm(dataloader_val):\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JPIG9Zq-UXm6",
    "outputId": "263aaf93-7cf4-41e4-9e28-b1deeea0ff29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparksandpromotions                7812\n",
       "navigation                         6155\n",
       "stock                              5977\n",
       "checkoutandlogin                   4623\n",
       "productrange                       4338\n",
       "deliveryinformationandmyaccount    3594\n",
       "missingcontentorimagery            2715\n",
       "orderandcommunication              2548\n",
       "search                             2337\n",
       "Name: Sub Reason, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sub Reason'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "91ba28c246424f078c02dda420bdd7eb",
      "df9d28c8481449c3bca095504e3f7d5b",
      "915cf635c1214ab0b9cdc8fd587a12f9",
      "23701336fdb24bdb8a17e50d61f847fa",
      "d427e05d897a4301b09b63f25b97dcea",
      "b396f696968846b890b7be16cf750846",
      "d00b4101236d44d899670789dd7906e5"
     ]
    },
    "id": "KC0WA2ALD7OK",
    "outputId": "fb8c9201-81bc-4a26-e7ca-d1e4837bc4ad"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ba28c246424f078c02dda420bdd7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d427e05d897a4301b09b63f25b97dcea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=10246.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Epoch {epoch}\n",
      "\r",
      "Training loss: 0.9376589711014938\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b396f696968846b890b7be16cf750846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3121.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: stock\n",
      "Accuracy: 1221/1424\n",
      "\n",
      "Class: orderandcommunication\n",
      "Accuracy: 420/579\n",
      "\n",
      "Class: search\n",
      "Accuracy: 344/566\n",
      "\n",
      "Class: navigation\n",
      "Accuracy: 1177/1471\n",
      "\n",
      "Class: deliveryinformationandmyaccount\n",
      "Accuracy: 542/815\n",
      "\n",
      "Class: sparksandpromotions\n",
      "Accuracy: 1611/1819\n",
      "\n",
      "Class: productrange\n",
      "Accuracy: 771/1012\n",
      "\n",
      "Class: missingcontentorimagery\n",
      "Accuracy: 531/632\n",
      "\n",
      "Class: checkoutandlogin\n",
      "Accuracy: 845/1043\n",
      "\n",
      "\r",
      "Validation loss: 0.7737201620149194\n",
      "\r",
      "f1 score (weighted): 0.7965717678792011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00b4101236d44d899670789dd7906e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=10246.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "    progress_bar = tqdm(dataloader_train,\n",
    "                        desc=\"Epoch {:1d}\".format(epoch),\n",
    "                        leave=False,\n",
    "                        disable=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids'       : batch[0],\n",
    "            'attention_mask'  : batch[1],\n",
    "            'labels'          : batch[2]\n",
    "        }\n",
    "    \n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix( {'training_loss': '{:3f}'.format(loss.item() / len(batch))} )\n",
    "\n",
    "    torch.save(model.state_dict(), 'BERT_ft_epoch{}.model'.format(epoch))\n",
    "    tqdm.write('\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    tqdm.write('Training loss: {}'.format(loss_train_avg))\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    val_acc=accuracy_per_class(predictions, true_vals)\n",
    "    \n",
    "    tqdm.write('Validation loss: {}'.format(val_loss))\n",
    "    tqdm.write('f1 score (weighted): {}'.format(val_f1))\n",
    "    # tqdm.write(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hA1Hk8QBD7ON"
   },
   "outputs": [],
   "source": [
    "\n",
    "# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "#                                                       num_labels=len(label_dict),\n",
    "#                                                       output_attentions=False,\n",
    "#                                                       output_hidden_states=False)\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sauK2dq0BJzf",
    "outputId": "0b32bc58-f9ed-4791-c80b-dff1104035e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am b2.', 'a', 'hello i am going to kill you.']"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from nltk import sent_tokenize\n",
    "sen=sent_tokenize('I am b2. hello i am going to kill you. a ')\n",
    "random.shuffle(sen)\n",
    "sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "wSVFylHWBS6q",
    "outputId": "204034f0-0437-4d57-aeed-4290f991e4d3"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1386409f806e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: shuffle() takes from 2 to 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "random.shuffle(['a','b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSG1lVbYB0l4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "91ba28c246424f078c02dda420bdd7eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_915cf635c1214ab0b9cdc8fd587a12f9",
       "IPY_MODEL_23701336fdb24bdb8a17e50d61f847fa"
      ],
      "layout": "IPY_MODEL_df9d28c8481449c3bca095504e3f7d5b"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
